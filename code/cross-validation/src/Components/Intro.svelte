<script>
</script>

<section>
  <p class="body-text">
    Often in machine learning we want to compare and evaluate models without
    having to wait for new data. Of course, we could just evaluate predictions
    on the same data that we used to fit our model’s parameters, but this will
    give unreliable assessments of our model's ability to generalize. Thus, we’d
    like to find a way to assess the generalization capabilities of our model
    without waiting for new data. This article discusses one of the most common
    approaches for this task: *cross-validation*. We'll first discuss the
    approach we previously learned, introduce some new approaches, and discuss
    what values of k are commonly selected and why.
  </p>
</section>

<style>
  /* mobile */
  @media screen and (max-width: 950px) {
  }
</style>
